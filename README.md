# oneAPI-GenAI-Hackathon-2023 - Hack2Skill

Welcome to the official repository for the oneAPI-GenAI-Hackathon-2023 organized by Hack2Skill!

## Getting Started

To get started with the oneAPI-GenAI-Hackathon-2023 repository, follow these steps:

### Submission Instruction:
  1. Fork this repository
  2. Create a folder with your Team Name
  3. Upload all the code and necessary files in the created folder
  4. Upload a **README.md** file in your folder with the below-mentioned information.
  5. Generate a Pull Request with your Team Name. (Example: submission-XYZ_team)

### README.md must consist of the following information:

#### Team Name - **PersonaProdigies**
#### Problem Statement - **Create an Adaptive Language Model (LLM) for a versatile AI platform, catering to a diverse range of user personas, including families, startup entrepreneurs, introverts, and more. This LLM should intelligently preserve context and customize interactions to suit the unique thoughts and preferences of each persona, delivering an enhanced user experience across a broad spectrum of users.**
#### Team Leader Email - **avvasriya@gmail.com**

### A Brief of the Prototype:
  This section must include UML Diagrams and prototype description
  
### Tech Stack: 
   1. Machine Learning Framework with oneAPI:
   - Intel oneAPI Deep Neural Network Library (oneDNN): This library provides optimized building blocks for deep learning applications, ensuring efficient execution on Intel architectures.

2. Parallel Computing with oneAPI:
   - Intel oneAPI Threading Building Blocks (oneTBB): This library helps with parallelizing computations, providing a scalable and efficient parallel programming model.

3. Data Processing with oneAPI:
   - Intel oneAPI Data Analytics Library (oneDAL): This library is designed for big data processing and analytics, providing optimized algorithms for data manipulation.

4. Optimized Math Operations:
   - Intel oneAPI Math Kernel Library (oneMKL): Incorporate oneMKL for optimized mathematical operations, enhancing the performance of your computations.

5. Vectorization with oneAPI:
   - Intel oneAPI DPC++ Compiler: Use this compiler to write Data Parallel C++ (DPC++) code that can leverage vectorization for improved performance.

6. Scalable Communication:
   - Intel oneAPI Collective Communications Library (oneCCL): If you're working with distributed computing, oneCCL can help optimize communication between nodes for better scalability.

7. Compatibility with Heterogeneous Architectures:
   - Intel oneAPI Base Toolkit: This toolkit includes a comprehensive set of tools and libraries that can be used across different Intel architectures, providing flexibility and compatibility.
   
### Step-by-Step Code Execution Instructions:
  1. *User Persona Interface:*
   - Develop an intuitive graphical interface that allows users to select and switch between different personas (e.g., family member, startup entrepreneur, introvert).
   - Include options for users to personalize their profiles based on persona preferences.

2. *Input Simulation:*
   - Create an interactive chat or voice-based input system that mimics real user interactions.
   - Implement both text and voice input options to demonstrate the LLM's versatility.

3. *Context Preservation:*
   - Showcase a conversation history feature that retains context from previous interactions.
   - Highlight how the LLM adapts responses by referring to the context, creating a dynamic and engaging conversation.

4. *Customization:*
   - Illustrate how the AI system tailors responses based on the selected user persona.
   - Show persona-specific customization through sample interactions that reflect unique language styles and content preferences.

5. *Feedback Mechanism:*
   - Implement a user feedback form or mechanism within the prototype, enabling users to provide real-time input on their experiences.
   - Display how feedback is collected and used for model improvements.

6. *Performance Metrics:*
   - Display real-time performance metrics such as response accuracy, response time, and user satisfaction ratings.
   - Use visual elements like charts and graphs to make these metrics easily understandable.

7. *Integration:*
   - Simulate the integration of your Adaptive Language Model into an AI platform by including additional components like a voice assistant or chatbot.
   - Show how the LLM seamlessly interacts with other AI features.

8. *User Experience Testing:*
   - Involve hackathon judges or other participants in a live demonstration of the prototype.
   - Encourage participants to test different personas and provide feedback on inclusivity, personalization, and overall experience.

9. *Deployment Simulation:*
   - Present a simulated deployment environment to give a glimpse of how the model works in a live AI platform.
   - Illustrate how it maintains context and customizes responses in a production-like setup.

10. *Continuous Improvement:*
    - Demonstrate how the prototype accommodates updates and adapts to changing language trends.
    - Show how the model can integrate new data and respond to user feedback for ongoing improvement.
  
### Future Scope:
   Write about the scalability and futuristic aspects of the prototype developed
